+++
date = '2026-01-14T17:16:12+08:00'
draft = false
title = '万能机器'
+++

2024年，我花了不少时间研究各种AI产品的"技能系统"。这些系统看起来很神奇：你让AI做PPT，它就会调用"PPT技能"；让它写文档，就调用"文档技能"。
直到有一天我打开那些技能文件看了看。
里面就是一堆文本。纯粹的提示词，用markdown写的。所谓的"技能"，不过是在执行任务前，把一份说明书塞进上下文窗口。
没有任何魔法。

但这个发现让我开始思考一个更本质的问题：如果技能是提示词，那LLM编程是什么？
答案很简单：提示词编程。
传统编程是用代码控制机器行为。LLM编程是用自然语言控制模型行为。两者的共同点都是约束与引导——只是介质从形式语言变成了自然语言。
顺着这个思路往下想，当前所谓的"AI应用开发"本质上就是：

System Prompt = 程序主体
Few-shot Examples = 测试用例
Tools = 外部API
Context Window = 运行时内存
Skills/RAG = 动态链接库

只不过这门"语言"的解释器是个概率模型，所以执行结果有随机性。

这里有一个有趣的trade-off。
传统编程：确定性执行，有限指令集。
LLM编程：概率性执行，无限指令空间。
听起来概率性是个缺点。但仔细想想，收益远大于代价。
传统编程里，你只能在语言设计者预设的指令集内操作。想让机器做一件事，必须把意图翻译成那套形式语言能表达的东西。翻译不了的，就做不了。
现在指令空间打开了。任何人类能用语言表达的意图，理论上都可以成为指令。
这不是量变，是质变。编程从"学会机器的语言"变成了"让机器理解人的语言"。

但是，不管我们怎么包装这种"智能"，底层仍然是一台冯诺依曼机器。
把类比画出来：

存储器 → Context Window
控制器 → Attention机制
运算器 → FFN层
指令流 → Token序列的自回归生成
程序计数器 → 当前生成位置

一次forward pass就是一次确定性计算。所谓"概率"只在最后采样那一步引入。给定相同权重、相同输入、相同随机种子，输出完全确定。
冯诺依曼架构有一个核心洞见：程序和数据用同一种方式表示，存储在同一个空间。
LLM把这个推向了极致。Prompt、context、知识、指令，全部是token序列，没有本体论上的区分。这既是它的力量来源，也是它的脆弱性来源。
机器还是那台机器。只是指令集从几百条变成了整个自然语言空间。

这个认识有一个重要推论：传统软件工程的那套东西，不但没有过时，反而更重要了。
需求文档？以前需求写得模糊，代码可能写错，但至少稳定地错。现在需求写得模糊，模型会创造性地发挥，每次还不一样。
架构设计？上下文窗口如何分配，多步任务如何拆解，失败如何回退，状态如何持久化——这些就是架构问题，只是抽象层变了。
自动化测试？确定性系统测一遍过了就过了。概率系统必须多次采样看分布、边界条件覆盖、回归测试防漂移、对抗测试防注入。测试成本是指数级上升。
越是概率性，越需要工程纪律。
以前写差了，机器老实执行你的错误。现在写差了，模型帮你补全更多的错误。

但这里有一件真正令人兴奋的事。
传统计算机的问题是rewire成本太高。需求变了，要重新分析、设计、编码、测试、部署。整个翻译链条要重走一遍。
LLM改变了这一点。
改个prompt就能改变行为。上下文实时注入就能适应环境。不需要停机，不需要重编译。
更关键的是，这台机器能表征自己的认知边界，并据此调整行为。传统程序不知道自己不知道什么。LLM可以说"我不确定"，然后选择搜索或询问。
把这些加起来，你会发现一种新的可能性：一台能持续感知任务需求、外部环境、自身认知状态，并据此自我调整的机器。
这不是"执行固定程序的机器"，而是在意图-环境-自我的三角关系中动态塑形的实体。
一种真正的数字智能体。

当然，这里有一个重要的区分。
LLM有两种使用模式。
第一种是开环的：人给出指令，LLM给出输出，输出本身就是目的。比如一场开放式讨论，比如文学创作，比如医疗咨询。这些任务没有"正确答案"，价值在过程本身。
第二种是闭环的：输出必须收敛到某个确定状态。比如写一段能跑的代码，比如填一张表格。这时候就需要验证、修正、再验证，直到达到目标。
开环场景是LLM的天然主场。它的开放性和创造性正好发挥作用。
闭环场景就麻烦了。如果让人来做闭环——验证、反馈、修正——成本很高，而且痛苦。如果让机器来做闭环，就需要一套成熟的工程框架。
这就是冯诺依曼隐喻的价值所在。
你当然可以用其他隐喻来理解LLM。语言游戏、神经系统、热力学系统、市场、生态系统……这些隐喻各有洞见，能帮你理解LLM的某些特性。
但如果你的目标是造东西，是让这台机器自动完成闭环任务，那冯诺依曼范式几乎是唯一成熟的选择。
它提供了几十年积累的工程经验：如何分解任务，如何管理状态，如何处理异常，如何测试验证。这些经验可以直接迁移。
哲学上可以有很多隐喻。工程上只有一条可行路径。

那么，未来会不会有一天，我们提出需求，LLM一次性就解决了？
会，但只在一小部分任务上。
按照80/20原则，80%的人在做20%的任务。甚至更极端：98%的人在做2%的事情。这2%的热点任务，需求模式固定，解空间有限，完全可以一次性解决。
但一旦进入长尾，情况就完全不同了。
比如反复修改PPT的某个局部。用户说"这里不太对"，但什么是"对"？他自己也说不清楚。他需要看到一版，说"不对"；再看一版，说"接近了"；再调整，再看……
这个过程不是低效。这是人类搞清楚自己到底要什么的唯一方式。
长尾任务的本质是：问题空间爆炸，需要不断剪枝。而每一次剪枝都是一个选择，每一个选择都在定义"什么是好的"。
这些cut不能外包给机器。因为它们就是需求本身。

我喜欢用吃来打比方。
在KFC吃饱很容易。热量充足，口味标准化，全球任何一家店都差不多。这是一个收敛问题，有正确答案。
但成为王世襄那样的美食家很难。什么是好吃？为什么这道菜用这种火候？为什么这个食材要在这个季节？深入下去，里面全是选择，全是品味，全是问题空间的爆炸。
任何领域都有这个分叉。写代码：能跑 vs 优雅。做设计：能用 vs 有品味。写文章：通顺 vs 有洞见。
前者可以自动化。后者必然是长尾，必然需要人做cut。

所以LLM真正改变的是什么？
不是让人类不用思考。而是把瓶颈从"能不能做到"转移到"想要什么"。
以前你有一个想法，但不会写代码、不会做PPT、不会画图——想法卡在执行层。
现在执行层被打通了。卡点变成了：你到底想要什么？你能不能在那个巨大的可能性空间里做出有品味的cut？
设计能力、品味、判断力——这些"软"的东西，反而成了最硬的壁垒。
会用LLM生成一百个方案不难。难的是知道哪个是对的，以及为什么。

但这里有一个更大的可能性。
当前大多数AI产品的问题是：它们只是更快的KFC。批量生成，一次性交付，效率导向。用户来，用户走，系统什么都没留下。
真正的突破不在于让KFC更快。而在于：这台机器能不能在长尾中跟随用户的cut，逐渐理解"这个人觉得什么是好的"，最终evolve成这个用户的王世襄？
这需要三个阶段。
第一阶段是KFC。解决热点任务，快速、标准化，零门槛入口。这是基础。
第二阶段是学徒。在长尾任务中跟随人类cut，记住用户的选择模式，积累对"好"的理解。这是关键转折。
第三阶段是王世襄。不再只是执行，而是能主动提出高质量的cut。成为真正的协作者，而非工具。
王世襄之所以是王世襄，不是因为他吃得多，而是他在无数次选择中形成了一套内化的判断体系。
好的智能体应该能做同样的事——在与特定用户的长期协作中，evolve出针对这个人、这个领域的品味模型。
这才是真正的个人AI。不是一个通用工具碰巧知道你的名字，而是一个在你的问题空间里和你一起做过无数次cut、逐渐懂得你要什么的协作实体。

所以我们现在站在一个有趣的位置。
一方面，LLM打开了一个全新的可能性空间。指令集从有限变成无限，rewire成本下降了几个数量级，机器开始能感知和适应。
另一方面，热点任务的自动化只是起点。真正的价值在长尾，在那些需要反复cut的地方。而驾驭长尾的方法，仍然是那套古老的软件工程，加上一个新东西：让机器学会跟随人类的品味。
我们有了一台万能机器。但它的终极形态不是更快的KFC，而是能陪你一起成长的王世襄。
KFC可以开遍全球。王世襄只有一个。
但如果这台机器能在与你的协作中evolve，那每个人都可以有自己的王世襄。
这才是真正的new paradigm。